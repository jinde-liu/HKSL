{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-de53c1defff7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-de53c1defff7>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    from ../../mypath import Path\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from mypath import Path\n",
    "from torchvision import transforms\n",
    "from dataloaders import custom_transforms as tr\n",
    "\n",
    "class VOCSegmentation(Dataset):\n",
    "    \"\"\"\n",
    "    PascalVoc dataset\n",
    "    \"\"\"\n",
    "    NUM_CLASSES = 21\n",
    "\n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 base_dir=Path.db_root_dir('pascal'),\n",
    "                 split='train',\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param base_dir: path to VOC dataset directory\n",
    "        :param split: train/val\n",
    "        :param transform: transform to apply\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._base_dir = base_dir\n",
    "        self._image_dir = os.path.join(self._base_dir, 'JPEGImages')\n",
    "        self._cat_dir = os.path.join(self._base_dir, 'SegmentationClass')\n",
    "\n",
    "        if isinstance(split, str):\n",
    "            self.split = [split]\n",
    "        else:\n",
    "            split.sort()\n",
    "            self.split = split\n",
    "\n",
    "        self.args = args\n",
    "\n",
    "        _splits_dir = os.path.join(self._base_dir, 'ImageSets', 'Segmentation')\n",
    "\n",
    "        self.im_ids = []\n",
    "        self.images = []\n",
    "        self.categories = []\n",
    "\n",
    "        for splt in self.split:\n",
    "            with open(os.path.join(os.path.join(_splits_dir, splt + '.txt')), \"r\") as f:\n",
    "                lines = f.read().splitlines()\n",
    "\n",
    "            for ii, line in enumerate(lines):\n",
    "                _image = os.path.join(self._image_dir, line + \".jpg\")\n",
    "                _cat = os.path.join(self._cat_dir, line + \".png\")\n",
    "                assert os.path.isfile(_image)\n",
    "                assert os.path.isfile(_cat)\n",
    "                self.im_ids.append(line)\n",
    "                self.images.append(_image)\n",
    "                self.categories.append(_cat)\n",
    "\n",
    "        assert (len(self.images) == len(self.categories))\n",
    "\n",
    "        # Display stats\n",
    "        print('Number of images in {}: {:d}'.format(split, len(self.images)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _img, _target = self._make_img_gt_point_pair(index)\n",
    "        sample = {'image': _img, 'label': _target}\n",
    "\n",
    "        for split in self.split:\n",
    "            if split == \"train\":\n",
    "                return self.transform_tr(sample)\n",
    "            elif split == 'val':\n",
    "                return self.transform_val(sample)\n",
    "\n",
    "\n",
    "    def _make_img_gt_point_pair(self, index):\n",
    "        _img = Image.open(self.images[index]).convert('RGB')\n",
    "        _target = Image.open(self.categories[index])\n",
    "\n",
    "        return _img, _target\n",
    "\n",
    "    def transform_tr(self, sample):\n",
    "        composed_transforms = transforms.Compose([\n",
    "            tr.RandomHorizontalFlip(),\n",
    "            tr.RandomScaleCrop(base_size=self.args.base_size, crop_size=self.args.crop_size),\n",
    "            tr.RandomGaussianBlur(),\n",
    "            tr.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            tr.ToTensor()])\n",
    "\n",
    "        return composed_transforms(sample)\n",
    "\n",
    "    def transform_val(self, sample):\n",
    "\n",
    "        composed_transforms = transforms.Compose([\n",
    "            tr.FixScaleCrop(crop_size=self.args.crop_size),\n",
    "            tr.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            tr.ToTensor()])\n",
    "\n",
    "        return composed_transforms(sample)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'VOC2012(split=' + str(self.split) + ')'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from dataloaders.utils import decode_segmap\n",
    "    from torch.utils.data import DataLoader\n",
    "    import matplotlib.pyplot as plt\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args()\n",
    "    args.base_size = 513\n",
    "    args.crop_size = 513\n",
    "\n",
    "    voc_train = VOCSegmentation(args, split='train')\n",
    "\n",
    "    dataloader = DataLoader(voc_train, batch_size=5, shuffle=True, num_workers=0)\n",
    "\n",
    "    for ii, sample in enumerate(dataloader):\n",
    "        for jj in range(sample[\"image\"].size()[0]):\n",
    "            img = sample['image'].numpy()\n",
    "            gt = sample['label'].numpy()\n",
    "            tmp = np.array(gt[jj]).astype(np.uint8)\n",
    "            segmap = decode_segmap(tmp, dataset='pascal')\n",
    "            img_tmp = np.transpose(img[jj], axes=[1, 2, 0])\n",
    "            img_tmp *= (0.229, 0.224, 0.225)\n",
    "            img_tmp += (0.485, 0.456, 0.406)\n",
    "            img_tmp *= 255.0\n",
    "            img_tmp = img_tmp.astype(np.uint8)\n",
    "            plt.figure()\n",
    "            plt.title('display')\n",
    "            plt.subplot(211)\n",
    "            plt.imshow(img_tmp)\n",
    "            plt.subplot(212)\n",
    "            plt.imshow(segmap)\n",
    "\n",
    "        if ii == 1:\n",
    "            break\n",
    "\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
